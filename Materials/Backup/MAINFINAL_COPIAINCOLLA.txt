#include <opencv2/opencv.hpp>
#include <opencv2\highgui\highgui.hpp>
#include <opencv2/dnn.hpp>
#include <opencv2/dnn/shape_utils.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>
#include <algorithm>
#include <cstdlib>
#include <stdio.h>
#include <stdlib.h>
#include <vector>
#include <iostream>
#include <math.h>
#include <fstream>
#include <opencv2/objdetect.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/videoio.hpp>
#include <iomanip>


using namespace std;
using namespace cv;
using namespace cv::dnn;


static const char* about =
"This sample uses You only look once (YOLO)-Detector (https://arxiv.org/abs/1612.08242) to detect objects on camera/video/image.\n"
"Models can be downloaded here: https://pjreddie.com/darknet/yolo/\n"
"Default network is 416x416.\n"
"Class names can be downloaded here: https://github.com/pjreddie/darknet/tree/master/data\n";
static const char* params_yolo =
"{ help           | false | print usage         }"
"{ cfg			  |		  | C:/Users/docdo/Documents/GitHub/darknet/cfg/yolov3.cfg }"
//"{ cfg            |       | model configuration }"
//"{ model          |       | model weights       }"
"{ model		  |		  | C:/Users/docdo/Documents/GitHub/CV2019_Project/Materials/yolov3.weights }"
"{ camera_device  | 0     | camera device number}"
"{ source         |       | video or image for detection}"
"{ min_confidence | 0.24  | min confidence      }"
"{ class_names    |       | C:/Users/docdo/Documents/GitHub/darknet/data/coco.names }";

const int SMOOTHING_VAL = 5; // Parameter for averaging window filter, bigger is this and more smoothed is the result
const double PI = 3.141592653;



bool isContained(Point2f p, Rect r);
void drawArrow(Mat image, Point start, Point end, Scalar color, int arrow_magnitude, int thickness, int line_type, int shift);
float euclideanDistP(Point& p, Point& q);
float euclideanDist(Point2f& p, Point2f& q);
vector<int> mode(vector<float> all_dist);
void drawDisplacement(Mat img, vector<Point2f> keypointsCur, vector<Point2f> keypointsPrev, vector<float> allDisp);

struct TransformParam
{
	TransformParam() {}
	TransformParam(double _dx, double _dy) {
		dx = _dx;
		dy = _dy;
	}

	double dx;
	double dy;
};

struct Trajectory
{
	Trajectory() {}
	Trajectory(double _x, double _y) {
		x = _x;
		y = _y;
	}

	double x;
	double y;
};

class Person{
private:
	int id;
 public:
	Point2f center;
	Rect ROI;
	vector<Point2f> foreground_cur_people;
	vector<Point2f> foreground_prev_people;
	Point2f arrow_tail;
	Point2f arrow_head;
	
	vector<float> all_dist;

	Person() : center(), ROI(), arrow_tail(), arrow_head(), id() {
		
	};
	Person(Rect _ROI, int _id) {
		ROI = _ROI;
		center = Point2f(ROI.x + ROI.width / 2, ROI.y + ROI.height / 2);
		arrow_tail = center;
		id = _id;
	};
	Person(Rect _ROI, vector<Point2f> _foreGnd_cur, vector<Point2f> _foreGnd_prev, Point2f _arrow_head, int _id) {
		 
		ROI = _ROI; 
		foreground_cur_people = _foreGnd_cur;
		foreground_prev_people = _foreGnd_prev;
		center = Point2f(ROI.x + ROI.width / 2, ROI.y + ROI.height / 2);
		arrow_tail = center;
		arrow_head = _arrow_head;
		
		for (int i = 0; i < foreground_cur_people.size(); i++) {
			all_dist.push_back(euclideanDist(foreground_cur_people[i], foreground_prev_people[i]));
		}
	};
	void initID(int _id) {
		id = _id;
	};
	int getID() {
		return id;
	};
};




int main(int argc, char **argv)
{

	CommandLineParser parser(argc, argv, params_yolo);
	if (parser.get<bool>("help"))
	{
		cout << about << endl;
		parser.printMessage();
		return 0;
	}
	
	String modelConfiguration = "C:/Users/docdo/Documents/GitHub/darknet/cfg/yolov2.cfg";//parser.get<String>("cfg");
	String modelBinary = "C:/Users/docdo/Documents/GitHub/CV2019_Project/Materials/yolov2.weights";//parser.get<String>("model");
	dnn::Net net = readNetFromDarknet(modelConfiguration, modelBinary);
	if (net.empty())
	{
		cerr << "Can't load network by using the following files: " << endl;
		cerr << "cfg-file:     " << modelConfiguration << endl;
		cerr << "weights-file: " << modelBinary << endl;
		cerr << "Models can be downloaded here:" << endl;
		cerr << "https://pjreddie.com/darknet/yolo/" << endl;
		exit(-1);
	}

	//Open video file and return 0 if the file don't exist
	VideoCapture cap;
	
	cap.open("21.mp4");
	if (!cap.isOpened())
	{
		cout << "Couldn't open image or video: " << endl;//<< parser.get<String>("video") << endl;
		return -1;
	}

	//Create a Matrix that will be contain one frame of the video
	Mat cur, cur_grey;
	Mat prev, prev_grey;

	cap >> cur;

	//Enable the record of the output video and the trajectory video
	VideoWriter recordOutput("../Output_yolo.avi", CV_FOURCC('D', 'I', 'V', 'X'), 30, cur.size(), true);
	if (!recordOutput.isOpened())
		return -1;

	vector<string> classNamesVec;
	ifstream classNamesFile("C:/Users/docdo/Documents/GitHub/darknet/data/coco.names");//parser.get<String>("class_names").c_str());
	if (classNamesFile.is_open())
	{
		string className = "";
		while (std::getline(classNamesFile, className))
			classNamesVec.push_back(className);
	}

	// Create a txt file with the eleborated data
	ofstream out_transform("prev_to_cur_transformation.txt");
	ofstream out_trajectory("trajectory.txt");

	Mat traj(Size(cur.cols, cur.rows), CV_8UC3, Scalar(0, 0, 0));

	//Gain constant for correct the magnetude of the arrows and the space of the grid
	int gain_dis = 10;
	float gain_tra = .5;
	int gain_sm = 10;
	int dist = 50;

	//Point that will contain the coordinate of the arrows
	Point pt2, pt3, pt3prev, pt4, pt2_fore, pt4_fore;
	Point center;

	center.x = cur.cols / 2;
	center.y = cur.rows / 2;

	//Setting the trajectory starting from the middle of image and normalized with the gain constant
	double x = traj.cols / 2 + traj.cols*gain_tra;
	double y = traj.rows / 2 + traj.rows*gain_tra;
	
	cap >> prev;

	//Convert the original video in to grayscale video
	cvtColor(prev, prev_grey, COLOR_BGR2GRAY);
	// Now I get previous to current frame transformation for all frames
	vector <TransformParam> prev_to_cur_transform, prev_to_cur_transform_fore;

	int k = 1;
	int max_frames = cap.get(CV_CAP_PROP_FRAME_COUNT);
	Mat last_T, last_T_fore;
	
	vector<float> average_prev;
	vector<Point2f> buffer;
	vector<Person> people;
	   	  
	while (true) {

		cap >> cur; // get a new frame from camera/video or read image
		//imshow("frame", frame);

		Mat cur_yolo;
		cur_yolo = cur;
		if (cur_yolo.empty())
		{
			waitKey();
			break;
		}
		if (cur_yolo.channels() == 4)
			cvtColor(cur_yolo, cur_yolo, COLOR_BGRA2BGR);

		Mat inputBlob = blobFromImage(cur_yolo, 1 / 255.F, Size(608, 608), Scalar(), true, false); //Convert Mat to batch of images
		net.setInput(inputBlob, "data");                   //set the network input
		Mat detectionMat = net.forward();   //compute output
		vector<double> layersTimings;
		double freq = getTickFrequency() / 1000;
		double time = net.getPerfProfile(layersTimings) / freq;
		//ostringstream ss;
		//ss << "FPS: " << 1000 / time << " ; time: " << time << " ms";
		//putText(cur, ss.str(), Point(20, 20), 0, 0.5, Scalar(0, 0, 255));
		float confidenceThreshold = 0.2;//parser.get<float>("min_confidence");
		
		vector<Rect> rect_final;
		for (int i = 0; i < detectionMat.rows; i++)
		{
			const int probability_index = 5;
			const int probability_size = detectionMat.cols - probability_index;
			float *prob_array_ptr = &detectionMat.at<float>(i, probability_index);
			size_t objectClass = max_element(prob_array_ptr, prob_array_ptr + probability_size) - prob_array_ptr;
			float confidence = detectionMat.at<float>(i, (int)objectClass + probability_index);
			if (confidence > confidenceThreshold)
			{
				float x = detectionMat.at<float>(i, 0);
				float y = detectionMat.at<float>(i, 1);
				float width = detectionMat.at<float>(i, 2);
				float height = detectionMat.at<float>(i, 3);
				int xLeftBottom = static_cast<int>((x - width / 2) * cur_yolo.cols);
				int yLeftBottom = static_cast<int>((y - height / 2) * cur_yolo.rows);
				int xRightTop = static_cast<int>((x + width / 2) * cur_yolo.cols);
				int yRightTop = static_cast<int>((y + height / 2) * cur_yolo.rows);
				Rect object(xLeftBottom, yLeftBottom,
					xRightTop - xLeftBottom,
					yRightTop - yLeftBottom);
				if ("person" == String(classNamesVec[objectClass])) {
					//rectangle(cur, object, Scalar(0, 255, 0));
					rect_final.push_back(object);
				}


			}


		}
		

		/////////////////////////////// YOLO FINISHED /////////////////////////////

		//Draw a grid
		traj = Scalar(0, 0, 0);
		int width = traj.size().width;
		int height = traj.size().height;

		for (int i = 0; i < height; i += dist)
			line(traj, Point(0, i), Point(width, i), cv::Scalar(255, 255, 255));

		for (int i = 0; i < width; i += dist)
			line(traj, Point(i, 0), Point(i, height), cv::Scalar(255, 255, 255));

		if (cur.data == NULL) {
			break;
		}

		cvtColor(cur, cur_grey, COLOR_BGR2GRAY);

		//Now I define the vectors that will be contain the good feature points of current end previus frame, the status and error of optical flow
		vector <Point2f> prev_corner, cur_corner;
		vector <Point2f> prev_corner2, cur_corner2;
		vector <uchar> status;
		vector <float> err;

		goodFeaturesToTrack(prev_grey, prev_corner, 500, 0.01, 20);  //Detect the good feature points. I pass the max number of point to return, the quality threshold and the max euclidean distance between two points

		/*for (int i = 0; i < size(prev_corner); i++) {
			drawMarker(cur, Point(prev_corner.at(i).x, prev_corner.at(i).y), Scalar(255, 255, 255));
		}
		*/
		calcOpticalFlowPyrLK(prev_grey, cur_grey, prev_corner, cur_corner, status, err);	//Compute the optical flow

		// I read all value returned by optial flow function and if the status is setted to false, I discard this value
		for (size_t i = 0; i < status.size(); i++) {
			if (status[i]) {
				prev_corner2.push_back(prev_corner[i]);
				cur_corner2.push_back(cur_corner[i]);

			}
		}

		//Compute the translation plus rotation of my 2D points
		Mat T = estimateRigidTransform(prev_corner2, cur_corner2, false);

		//In rare cases no transform is found. We'll just use the last known good transform.
		if (T.data == NULL) {
			last_T.copyTo(T);
		}

		T.copyTo(last_T);

		//Extract dx and dy from trasformation matrix
		double dx = T.at<double>(0, 2);
		double dy = T.at<double>(1, 2);
		float threshold = sqrt(dx*dx + dy * dy);
		prev_to_cur_transform.push_back(TransformParam(dx, dy));

		out_transform << k << " " << dx << " " << dy << " " << threshold << endl;	//Write in txt file

		cur.copyTo(prev);
		cur_grey.copyTo(prev_grey);

		cout << "Frame: " << k << "/" << max_frames << " - good optical flow: " << prev_corner2.size() << endl;	//Output on console

		vector <TransformParam> smoothed_displacement;

		//Performing the averaging window for smoothing the result of displace
		for (size_t i = 0; i < prev_to_cur_transform.size(); i++)
		{
			double sum_x = 0;
			double sum_y = 0;
			int count = 0;

			for (int j = -SMOOTHING_VAL; j <= SMOOTHING_VAL; j++) {
				if (i + j >= 0 && i + j < prev_to_cur_transform.size()) {
					sum_x += prev_to_cur_transform[i + j].dx;
					sum_y += prev_to_cur_transform[i + j].dy;

					count++;
				}
			}

			double avg_x = sum_x / count;
			double avg_y = sum_y / count;

			smoothed_displacement.push_back(TransformParam(avg_x, avg_y));

			//Assign the vaule of x and y in a point moltiplied by a gain factor 
			pt2.x = center.x + (-dx * gain_dis);
			pt2.y = center.y + (-dy * gain_dis);

			pt4.x = center.x + (-avg_x * gain_sm);
			pt4.y = center.y + (-avg_y * gain_sm);
		}

		//Now i extimate the trajectory with an incremental variable that add/subtract his status every iteration with the average flow value. 
		vector <Trajectory> trajectory;
		x -= (center.x - pt4.x) / gain_sm;
		y -= (center.y - pt4.y) / gain_sm;

		trajectory.push_back(Trajectory(x, y));

		out_trajectory << (k + 1) << " " << x << " " << y << endl;

		pt3.x = (x*gain_tra);
		pt3.y = (y*gain_tra);

		pt3prev.x = pt3.x + (dx*gain_tra);
		pt3prev.y = pt3.y + (dy*gain_tra);

		drawArrow(cur, center, pt2, Scalar(0, 0, 255), 9, 2, 8, 0);		//Draw displacement
		drawArrow(cur, center, pt4, Scalar(255, 0, 0), 9, 4, 8, 0);		//Draw displacement smooth
		drawArrow(traj, pt3prev, pt3, Scalar(0, 0, 255), 9, 3, 8, 0);	//Draw the trajectory

		vector<float> all_dist;
		vector<Point2f> dist_comp;
		for (size_t i = 0; i < cur_corner2.size(); i++) {
			all_dist.push_back(euclideanDist(cur_corner2[i], prev_corner2[i]));
			//out_transform << k << " " << cur_corner2[i].x-prev_corner2[i].x << "<-dx  " << cur_corner2[i].y-prev_corner2[i].y << "<-dy " << endl;	//Write in txt file
			dist_comp.push_back(Point2f(abs(cur_corner2[i].x - prev_corner2[i].x), abs(cur_corner2[i].y - prev_corner2[i].y)));
		}

		/////////////////////////////////////////////////////////////////////

		/////////////////////////////////////////////////////////////////////


		//	SCOMMENTA
		vector<Point2f> background, foreground_cur, foreground_prev;
		//float threshold = sqrt(dx*dx + dy*dy);//euclideanDistP(center, pt4);


		//cout << offset << endl;
		/*
		for (size_t i = 0; i < all_dist.size(); i++)
		{
			if (all_dist[i] <= (my_mode[0] + offset) && all_dist[i] >= (my_mode[0] - offset)) {
				//if (all_dist[i] <= (my_mode[0] + offset) && all_dist[i] >= (my_mode[0] - offset)) {
				background.push_back(cur_corner2[i]);
			}
			else {
				foreground_cur.push_back(cur_corner2[i]);
				foreground_prev.push_back(prev_corner2[i]);

			}

			if (abs(all_dist[i] - new_average) < (2 + threshold)) {
				background.push_back(cur_corner2[i]);
			}
			else {
				foreground_cur.push_back(cur_corner2[i]);
				foreground_prev.push_back(prev_corner2[i]);
			}


		}
		/*
		float sum_fore = 0;

		for (size_t i = 0; i < foreground_cur.size(); i++) {
			float dist_fore = euclideanDist(foreground_cur[i], foreground_prev[i]);

			sum_fore = sum_fore + dist_fore;
		}

		float average_fore = sum_fore / foreground_cur.size();

		for (size_t i = 0; i < foreground_cur.size(); i++) {
			if (euclideanDist(foreground_cur[i], foreground_prev[i]) > 2 * average_fore) {
				foreground_cur.erase(foreground_cur.begin() + i);
				foreground_prev.erase(foreground_prev.begin() + i);
			}
		}

		vector<float> fore_xAxis;
		for (int i = 0; i < foreground_cur.size(); i++) {
			fore_xAxis.push_back(foreground_cur[i].x);
		}
		if (k == 13) {
			int iiii = 0;
		}
		*/

		/* // SOLO PER 1 PERSONA
		vector<int> my_mode_xaxis;
		my_mode_xaxis = mode(fore_xAxis);
		drawMarker(cur, Point(my_mode_xaxis[0], cur.rows/2), Scalar(0, 0, 255));

		cout << "frame: " << k << endl;
		for (size_t i = 0; i < foreground_cur.size(); i++) {
			if (abs(my_mode_xaxis[0] - fore_xAxis[i]) > abs(my_mode_xaxis[0] - (cur.cols)/5)) {
				foreground_cur.erase(foreground_cur.begin() + i);
				foreground_prev.erase(foreground_prev.begin() + i);

				fore_xAxis.erase(fore_xAxis.begin() + i);
			}
		}
		*/

		vector<Point2f> belonging_features;
		for (size_t i = 0; i < rect_final.size(); i++) {

			for (size_t j = 0; j < cur_corner2.size(); j++) {
				if (isContained(cur_corner2[j], rect_final[i]) == true) {
					belonging_features.push_back(cur_corner2[j]);
					foreground_prev.push_back(prev_corner2[j]);
					foreground_cur.push_back(cur_corner2[j]);
				}

			}
			/*
			for (int j = 0; j < size(belonging_features); j++) {
				drawMarker(cur, Point(belonging_features.at(j).x, belonging_features.at(j).y), Scalar(0, 0, 255));
			}*/
			belonging_features.clear();
		}

		vector<float> all_dist_fore;
		vector<Point2f> dist_comp_fore;
		for (size_t i = 0; i < foreground_cur.size(); i++) {
			all_dist_fore.push_back(euclideanDist(foreground_cur[i], foreground_prev[i]));
			//out_transform << k << " " << cur_corner2[i].x-prev_corner2[i].x << "<-dx  " << cur_corner2[i].y-prev_corner2[i].y << "<-dy " << endl;	//Write in txt file
			dist_comp_fore.push_back(Point2f(abs(foreground_cur[i].x - foreground_prev[i].x), abs(foreground_cur[i].y - foreground_prev[i].y)));
		}


		vector<int> my_mode;
		if (all_dist.size() != 0) {
			my_mode = mode(all_dist);
					  
		//	cout << "LA MODA: " << my_mode[0] << " - " << my_mode[1] << endl;
		//	out_transform << k << " " << my_mode[0] << " " << my_mode[1] << endl;	//Write in txt file
			
			// 0 = mode[0], 1 = mode[1]
			float max = 0.0;
			float min = 0.0;
			float offset = abs(my_mode[1] - my_mode[0]);

			if (offset >= 4) {
				offset = 3;
			}
			else {
				offset = offset * 2.5; //*2
			}

			cout << "offset:" << offset << endl;




			float sum = 0;

			for (size_t i = 0; i < cur_corner2.size(); i++) {
				sum = sum + all_dist[i];
			}
			float average_cur = sum / all_dist.size();
			average_prev.push_back(average_cur);

			float new_sum = 0;

			for (size_t i = 0; i < average_prev.size(); i++) {
				new_sum = new_sum + average_prev[i];
			}
			float new_average = new_sum / average_prev.size();


			for (int i = 0; i < all_dist_fore.size(); i++) {
				if (all_dist_fore[i] <= my_mode[0] + offset) {
					all_dist_fore.erase(all_dist_fore.begin() + i);
					foreground_cur.erase(foreground_cur.begin() + i);
					foreground_prev.erase(foreground_prev.begin() + i);
					i = i - 1;
				}
			}

			float sum_fore = 0;

			for (size_t i = 0; i < foreground_cur.size(); i++) {
				float dist_fore = euclideanDist(foreground_cur[i], foreground_prev[i]);

				sum_fore = sum_fore + dist_fore;
			}

			float average_fore = sum_fore / foreground_cur.size();

			for (size_t i = 0; i < foreground_cur.size(); i++) {
				if (euclideanDist(foreground_cur[i], foreground_prev[i]) > 2.5 * average_fore) {
					foreground_cur.erase(foreground_cur.begin() + i);
					foreground_prev.erase(foreground_prev.begin() + i);
					i = i - 1;
				}
			}
		}


		/*
		for (size_t i = 0; i < foreground_cur.size(); i++) {
			drawArrow(cur, foreground_prev[i], foreground_cur[i], Scalar(0, 0, 255), 9, 2, 8, 0);
		}
		*/
		if (people.size() == 0) {
			for (int i = 0; i < rect_final.size(); i++) {
				Person p = Person(rect_final[i], i);
				people.push_back(p);
				//people[i].initID(i);
				////// assigning foreground
				for (int j = 0; j < foreground_cur.size(); j++) {
					if (isContained(foreground_cur[j], people[i].ROI) == true) {
						people[i].foreground_cur_people.push_back(foreground_cur[j]);
						people[i].foreground_prev_people.push_back(foreground_prev[j]);
					}	
				}
			}
		}
		else {
			for (int i = 0; i < people.size(); i++) {
				for (int j = 0; j < rect_final.size(); j++) {
					Point2f center_rect_final = Point2f(rect_final[j].x + rect_final[j].width / 2, rect_final[j].y + rect_final[j].height / 2);
					if (abs(people[i].center.x - center_rect_final.x) <= 75 || abs(people[i].ROI.x - rect_final[j].x) <= 75){//euclideanDist(people[i].center, center_rect_final) < 50) {
						people[i] = Person(rect_final[j], people[i].getID());
						rect_final.erase(rect_final.begin() + j);
						j = j - 1;
						for (int w = 0; w < foreground_cur.size(); w++) {
							if (isContained(foreground_cur[w], people[i].ROI) == true) {
								people[i].foreground_cur_people.push_back(foreground_cur[w]);
								people[i].foreground_prev_people.push_back(foreground_prev[w]);
							}
						}

					} /*else {
						Person p = Person(rect_final[j], people.size());
						people.push_back(p);
						//people[people.size() - 1].initID(people.size());
						for (int w = 0; w < foreground_cur.size(); w++) {
							if (isContained(foreground_cur[w], people[people.size() - 1].ROI) == true) {
								people[people.size() - 1].foreground_cur_people.push_back(foreground_cur[w]);
								people[people.size() - 1].foreground_prev_people.push_back(foreground_prev[w]);
							}
						}
					}*/
				}
			}
		}

		
		for (int i = 0; i < people.size(); i++) {
			stringstream _id;
			_id << people[i].getID();
			rectangle(cur, people[i].ROI, Scalar(0, 255, 0)); /// PROVARE A VISUALIZZARE INDICI
			rectangle(cur, Rect(people[i].ROI.x, people[i].ROI.y, 30, 10), Scalar(0,0,255));
			String label = _id.str();
			Size labelSize = getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, 0);
			Point cornerTxt = Point(people[i].ROI.x, people[i].ROI.y + labelSize.height);
			putText(cur, label, cornerTxt, FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255));
		}

		for (int i = 0; i < people.size(); i++) {
			for (int j = 0; j < people[i].foreground_cur_people.size(); j++) {
				drawArrow(cur, people[i].foreground_prev_people[j], people[i].foreground_cur_people[j], Scalar(255, 0, 0), 9, 2, 1, 0);
			}
		}

		/*
		if (foreground_cur.size() != 0) {
			//Compute the translation plus rotation of my 2D points
			Mat T_fore = estimateRigidTransform(foreground_prev, foreground_cur, false);

			//In rare cases no transform is found. We'll just use the last known good transform.
			if (T_fore.data == NULL) {
				last_T_fore.copyTo(T_fore);
			}

			T_fore.copyTo(last_T_fore);
			if (T_fore.data != NULL) {
				//Extract dx and dy from trasformation matrix
				double dx_fore = T_fore.at<double>(0, 2);
				double dy_fore = T_fore.at<double>(1, 2);

				prev_to_cur_transform_fore.push_back(TransformParam(dx_fore, dy_fore));

				out_transform << k << " " << dx_fore << " " << dy_fore << endl;	//Write in txt file

				//cur.copyTo(prev);
				//cur_grey.copyTo(prev_grey);

				//cout << "Frame: " << k << "/" << max_frames << " - good optical flow: " << prev_corner2.size() << endl;	//Output on console

				Point2f center_fore;
				center_fore = Point2f(rect_final[0].x + rect_final[0].width / 2, rect_final[0].y + rect_final[0].height / 2);


				vector<TransformParam> smoothed_displacement_fore;

				//Performing the averaging window for smoothing the result of displace
				for (size_t i = 0; i < prev_to_cur_transform_fore.size(); i++)
				{
					double sum_x = 0;
					double sum_y = 0;
					int count = 0;

					for (int j = -SMOOTHING_VAL; j <= SMOOTHING_VAL; j++) {
						if (i + j >= 0 && i + j < prev_to_cur_transform.size()) {
							sum_x += prev_to_cur_transform_fore[i + j].dx;
							sum_y += prev_to_cur_transform_fore[i + j].dy;

							count++;
						}
					}

					double avg_x = sum_x / count;
					double avg_y = sum_y / count;

					smoothed_displacement_fore.push_back(TransformParam(avg_x, avg_y));

					//Assign the vaule of x and y in a point moltiplied by a gain factor
					pt2_fore.x = center_fore.x + (dx_fore); //* gain_dis);
					pt2_fore.y = center_fore.y + (dy_fore);// *gain_dis);

					pt4_fore.x = center_fore.x + (avg_x);// *gain_sm);
					pt4_fore.y = center_fore.y + (avg_y);// *gain_sm);
				}

				//Now i extimate the trajectory with an incremental variable that add/subtract his status every iteration with the average flow value.
				
				vector <Trajectory> trajectory;
				x -= (center.x - pt4.x) / gain_sm;
				y -= (center.y - pt4.y) / gain_sm;

				trajectory.push_back(Trajectory(x, y));

				out_trajectory << (k + 1) << " " << x << " " << y << endl;

				k++;

				pt3.x = (x*gain_tra);
				pt3.y = (y*gain_tra);

				pt3prev.x = pt3.x + (dx*gain_tra);
				pt3prev.y = pt3.y + (dy*gain_tra);
				
				
				drawArrow(cur, center_fore, pt2_fore, Scalar(0, 0, 255), 9, 2, 8, 0);		//Draw displacement
				drawArrow(cur, center_fore, pt4_fore, Scalar(255, 0, 0), 9, 4, 8, 0);		//Draw displacement smooth

				
			}
		}
		*/
		//drawDisplacement(cur, foreground_cur, foreground_prev, all_dist);














		k++;
		imshow("YOLO: Detections", cur);
		recordOutput << cur;
		//imwrite("OUTPUTFRAME.jpg", frame);
		if (waitKey(1) >= 0) break;
	}
	return 0;


}
bool isContained(Point2f p, Rect r) {
	if ((p.x >= r.tl().x && p.x <= r.br().x) && (p.y >= r.tl().y && p.y <= r.br().y)) {
		return true;
	}
	else {
		return false;
	}
}
float euclideanDistP(Point& p, Point& q) {
	Point diff;
	diff.x = abs(p.x - q.x);
	diff.y = abs(p.y - q.y);
	//absdiff(p, q, diff);
	return (cv::sqrt(diff.x*diff.x + diff.y*diff.y));
}

float euclideanDist(Point2f& p, Point2f& q) {
	Point diff;
	diff.x = abs(p.x - q.x);
	diff.y = abs(p.y - q.y);
	//absdiff(p, q, diff);
	return (cv::sqrt(diff.x*diff.x + diff.y*diff.y));
}
void drawArrow(Mat image, Point start, Point end, Scalar color, int arrow_magnitude, int thickness, int line_type, int shift)
{
	//Draw the main line
	line(image, start, end, color, thickness, line_type, shift);

	//Compute the angle alpha
	double angle = atan2(start.y - end.y, start.x - end.x);

	//Compute the coordinates of the first segment
	start.x = (end.x + arrow_magnitude * cos(angle + PI / 4));
	start.y = (end.y + arrow_magnitude * sin(angle + PI / 4));

	//Draw the first segment
	line(image, start, end, color, thickness, line_type, shift);

	//Compute the coordinates of the second segment
	start.x = (end.x + arrow_magnitude * cos(angle - PI / 4));
	start.y = (end.y + arrow_magnitude * sin(angle - PI / 4));

	//Draw the second segment
	line(image, start, end, color, thickness, line_type, shift);
}

vector<int> mode(vector<float> all_dist) {
	int rating, j, h;
	float largest = 0;
	float modeValue1 = 0;
	float modeValue2 = 0;
	float min, max;
	min = all_dist[0];
	max = all_dist[0];
	vector<int> freq;

	for (int i = 0; i < all_dist.size(); i++) {
		if (all_dist[i] < 0) {
			all_dist.at(i) = 0;
		}
	}

	for (int i = 0; i < all_dist.size(); i++) {
		if (all_dist[i] <= min) {
			min = all_dist[i];
		}
		if (all_dist[i] >= max) {
			max = all_dist[i];
		}
	}
	int int_max = int(max) + 1;
	int int_min = int(min);

	if (int_min != 0) {
		for (int i = 0; i < int_min; i++) {
			freq.push_back(0);
		}
	}
	for (rating = int(min); rating <= int(max); rating++) {
		freq.push_back(0);
	}

	for (j = 0; j < all_dist.size(); j++) {
		freq.at(int(all_dist[j])) = freq[int(all_dist[j])] + 1;
	}

	for (rating = int(min); rating <= int(max); rating++) {
		if (freq[rating] > largest) {
			largest = freq[rating];
			modeValue1 = rating;
		}
	}



	freq.at(modeValue1) = 0;


	largest = 0;
	for (int i = 0; i < freq.size(); i++) {
		if (freq[i] > largest) {
			largest = freq[i];
			modeValue2 = i;
		}
	}
	vector<int> output;
	output.push_back(modeValue1);
	output.push_back(modeValue2);
	return output;

}

void drawDisplacement(Mat img, vector<Point2f> keypointsCur, vector<Point2f> keypointsPrev, vector<float> allDisp) {
	float averageDisp = 0.0;
	float sum = 0.0;
	for (int i = 0; i < allDisp.size(); i++) {
		sum = sum + allDisp[i];
	}
	averageDisp = sum / allDisp.size();

	float averagePosX = 0.0;
	sum = 0.0;
	for (int i = 0; i < keypointsCur.size(); i++) {
		sum = sum + keypointsCur[i].x;
	}
	averagePosX = sum / keypointsCur.size();

	float averagePosY = 0.0;
	sum = 0.0;
	for (int i = 0; i < keypointsCur.size(); i++) {
		sum = sum + keypointsCur[i].y;
	}
	averagePosY = sum / keypointsCur.size();

	Point2f posCur = Point2f(averagePosX, averagePosY);

	averagePosX = 0.0;
	sum = 0.0;
	for (int i = 0; i < keypointsPrev.size(); i++) {
		sum = sum + keypointsPrev[i].x;
	}
	averagePosX = sum / keypointsPrev.size();

	averagePosY = 0.0;
	sum = 0.0;
	for (int i = 0; i < keypointsPrev.size(); i++) {
		sum = sum + keypointsPrev[i].y;
	}
	averagePosY = sum / keypointsPrev.size();

	Point2f posPrev = Point2f(averagePosX, averagePosY);
	drawArrow(img, posPrev, posCur, Scalar(255, 0, 0), 9, 2, 8, 0);

}


